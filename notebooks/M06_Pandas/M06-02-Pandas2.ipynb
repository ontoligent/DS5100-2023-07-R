{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NB: Introducing Pandas II\n",
        "\n",
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.getsizeof(iris)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Lambda Functions with `.apply()`\n",
        "\n",
        "Apply a transformation to each record. Uses a `lambda` function.\n",
        "\n",
        "The `apply()` method should be used after you have established that you can't use a vectorized function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris['sepal_len_sq'] = iris.sepal_length.apply(lambda x: x**2)\n",
        "iris.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformation involving multiple columns. Uses `axis=1` to access columns.  \n",
        "Compute average of `sepal_length`, `sepal_width`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris['sepal_len_wid_avg'] = iris[['sepal_length','sepal_width']].apply(lambda x: (x.sepal_length+x.sepal_width)/2, axis=1)\n",
        "iris.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Vectorized Version**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%time iris.sepal_length**2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare to `.apply()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%time iris.sepal_length.apply(lambda x: x**2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation\n",
        "\n",
        "Involves one or more of:\n",
        "\n",
        "- splitting the data into groups\n",
        "- applying a function to each group\n",
        "- combining results\n",
        "\n",
        "### `.groupby()`\n",
        "\n",
        "Compute mean of each column, grouped (separately) by species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.groupby(\"species\").mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `pd.pivot_table()`\n",
        "\n",
        "Apply a function `aggfunc` to selected values grouped by columns\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)\n",
        "\n",
        "Compute mean sepal length for each species:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.pivot_table(iris, values=\"sepal_length\", columns=[\"species\"], aggfunc = np.mean)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stacking and Unstacking\n",
        "\n",
        "Similar to pivoting, but requires -- and takes advantage of -- indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_w_idx = iris.copy() \n",
        "\n",
        "## Give the original index a name\n",
        "iris_w_idx.index.name = 'obs_id'\n",
        "\n",
        "## Create a multi-index, using `species` as part of the key.\n",
        "iris_w_idx = iris_w_idx.reset_index().set_index(['species','obs_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_w_idx"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `.unstack()`\n",
        "\n",
        "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_wide = iris_w_idx.sepal_length.unstack(fill_value=0).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_wide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_wide.mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `.stack()`\n",
        "\n",
        "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_wide.T.stack().to_frame('sepal_length')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combining DataFrames\n",
        "\n",
        "### `pd.concat()`  \n",
        "\n",
        "Concatenate pandas objects along an axis.\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n",
        "\n",
        "Create two dfs and vertically stack them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(np.random.randn(3, 4))\n",
        "df2 = pd.DataFrame(np.random.randn(3, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Concat rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3 = pd.concat([df1, df2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Concat columns**\n",
        "\n",
        "This assumes that the indexes represent IDs of specific things or events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df4 = pd.concat([df1, df2], axis=1, keys=['foo', 'bar'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df4.foo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `.merge()`\n",
        "\n",
        "SQL-style joining of tables (DataFrames) -- although Pandas has a `.join()` method, too.\n",
        "\n",
        "Important parameters include:\n",
        "\n",
        "- `how` : type of merge {'left', 'right', 'outer', 'inner', 'cross'}, default ‘inner’\n",
        "- `on`  : names to join on\n",
        "        \n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
        "\n",
        "Create two tables, `left` and `right`. Then right join them on `key`.  \n",
        "Right join means include all records from table on right.  \n",
        "The `key` is used for matching up the records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##| tags: []\n",
        "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"lval\": [15, 22]})\n",
        "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"rval\": [4, 5, 8]})\n",
        "\n",
        "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
        "\n",
        "print('---left')\n",
        "print(left)\n",
        "print('\\n---right')\n",
        "print(right)\n",
        "print('\\n---joined')\n",
        "print(joined)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the NaN inserted into the record with key=asher, since the left table didn't contain the key.\n",
        "\n",
        "**Matching column names**  \n",
        "In this next example, the value columns have the same name: *val*.  Notice what happens to the column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##| tags: []\n",
        "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"val\": [15, 22]})\n",
        "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"val\": [4, 5, 8]})\n",
        "\n",
        "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
        "\n",
        "print('---left')\n",
        "print(left)\n",
        "print('\\n---right')\n",
        "print(right)\n",
        "print('\\n---joined')\n",
        "print(joined)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `.join()`\n",
        "\n",
        "An SQL-like joiner, but this one takes advantage of indexes.\n",
        "\n",
        "Give our dataframes indexes and distinctive columns names.\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left2 = left.set_index('key').rename(columns={'val':'val_1'})\n",
        "right2 = right.set_index('key').rename(columns={'val':'val_2'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "right2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "right2.join(left2) # Defaults to 'inner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "right2.join(left2, how='left')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "* Use **join** if you have shared indexes\n",
        "* Use **merge** if you do not have shared indexes\n",
        "* Use **concat** to combine based on shared indexes or columns\n",
        "\n",
        "## Reshape with `.reshape()`\n",
        "\n",
        "Changes the object's shape\n",
        "\n",
        "We illustrate creating pandas Series, extracting array of length 6, and reshaping to 3x2 array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## create a series \n",
        "ser = pd.Series([1, 1, 2, 3, 5, 8]) \n",
        "\n",
        "## extract values \n",
        "vals = ser.values \n",
        "\n",
        "print('orig data:', vals)\n",
        "print('orig type:', type(vals))\n",
        "print('orig shape:', vals.shape)\n",
        "\n",
        "## reshaping series\n",
        "reshaped_vals = vals.reshape((3, 2)) \n",
        "\n",
        "print('\\n reshaped vals:')\n",
        "print(reshaped_vals)\n",
        "print('\\n new type:', type(reshaped_vals))\n",
        "print('new shape:', reshaped_vals.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Including -1 as one of the dimensions tells numpy: infer this dimension from the data and the other dimensions.\n",
        "\n",
        "Example: enforce 3 columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vals.reshape(-1,3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enforce 3 rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vals.reshape(3,-1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTANT NOTE**  \n",
        "\n",
        "Notice the shape of original array: `(6,)`  \n",
        "This is a vector with one dimension, and is different from two-dimensional `(6,1)` array\n",
        "\n",
        "## Categoricals\n",
        "\n",
        "Categorical data takes discrete values where computation on the values does not make sense.  \n",
        "Zip code is a typical example.\n",
        "\n",
        "To include categoricals in models, they must be converted to numeric.  \n",
        "\n",
        "### `get_dummies()`\n",
        "Dummy code categorical data\n",
        "\n",
        "Important parameters: \n",
        "\n",
        "- `prefix`    : append prefix to column names (a good idea for later use)\n",
        "- `drop_first`: remove first level, as only `k-1` variables needed to represent `k` levels\n",
        "\n",
        "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cats = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_cats = pd.get_dummies(cats.breed, drop_first=True, prefix='breed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_cats"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice `burmese` was dropped (first level by alphabet) since it can be inferred.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
